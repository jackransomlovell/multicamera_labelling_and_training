{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feed9d5f",
   "metadata": {},
   "source": [
    "### Train an MMDetection Network\n",
    "- See [tutorial](https://github.com/open-mmlab/mmdetection/blob/main/demo/MMDet_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8bb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc15fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973efda-bf01-405b-af49-a56a1be27102",
   "metadata": {},
   "source": [
    "### Download checkpoint for a pretrained model (if desired)\n",
    "Alternatively, use a previous mouse model as a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e5d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_directory = Path(\"/n/groups/datta/tim_sainburg/datasets/scratch/pretrained_mm_models\")\n",
    "pretrained_model_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75575fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find models here: https://github.com/open-mmlab/mmdetection/tree/main/configs/rtmdet\n",
    "pretrain_model = \"rtmdet_s_8xb32-300e_coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9f6f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source activate /n/groups/datta/tim_sainburg/conda_envs/mmdeploy; mim download mmdet --config rtmdet_s_8xb32-300e_coco --dest /n/groups/datta/tim_sainburg/datasets/scratch/pretrained_mm_models\n"
     ]
    }
   ],
   "source": [
    "command = f\"source activate {Path(sys.executable).parents[1]}; mim download mmdet --config {pretrain_model} --dest {pretrained_model_directory.as_posix()}\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e23ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: activate: No such file or directory\n",
      "processing rtmdet_s_8xb32-300e_coco...\n",
      "\u001b[32mrtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth exists in /n/groups/datta/tim_sainburg/datasets/scratch/pretrained_mm_models\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/bin/mim\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/mim/commands/download.py\", line 70, in cli\n",
      "    download(package, configs, dest_root, check_certificate, dataset)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/mim/commands/download.py\", line 107, in download\n",
      "    return _download_configs(package, configs, dest_root,\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/mim/commands/download.py\", line 182, in _download_configs\n",
      "    config_obj.dump(saved_config_path)\n",
      "  File \"/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/mmengine/config/config.py\", line 1568, in dump\n",
      "    with open(file, 'w', encoding='utf-8') as f:\n",
      "PermissionError: [Errno 13] Permission denied: '/n/groups/datta/tim_sainburg/datasets/scratch/pretrained_mm_models/rtmdet_s_8xb32-300e_coco.py'\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bb3a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth\n",
      "rtmdet_s_8xb32-300e_coco.py\n",
      "rtmpose-m_8xb64-210e_ap10k-256x256.py\n",
      "rtmpose-m_simcc-ap10k_pt-aic-coco_210e-256x256-7a041aa1_20230206.pth\n"
     ]
    }
   ],
   "source": [
    "!ls {pretrained_model_directory.as_posix()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fad4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/n/groups/datta/tim_sainburg/datasets/scratch/pretrained_mm_models')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd52711-da6b-44bc-be9a-b7bc206aae85",
   "metadata": {},
   "source": [
    "### Parameters and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516ae23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rtmdet_small_8xb32-300e_coco_rat'\n",
    "\n",
    "# Where the COCO format dataset is located (created in the previous notebook)\n",
    "dataset_directory = Path(\"/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata\")\n",
    "\n",
    "# which config to use (this is what we base the config off of). Should be in the mmdeteciton repo. \n",
    "config_loc = Path('/n/groups/datta/tim_sainburg/projects/mmdetection/configs/rtmdet/rtmdet_s_8xb32-300e_coco.py')\n",
    "\n",
    "# which pretrained model to use (point to .pth file). Pretrained model should be the same model architecture. \n",
    "#pretrained_model = pretrained_model_directory / \"rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth\"\n",
    "pretrained_model = Path('/n/groups/datta/tim_sainburg/projects/24-01-05-multicamera_keypoints_mm2d/models/rtmdet/rtmdet_tiny_8xb32-300e_coco_24-01-05-11-25-00_102726/epoch_300.pth')\n",
    "use_pretrained_model = True\n",
    "\n",
    "# working directory (where model output is saved)\n",
    "output_directory = Path(\"/n/groups/datta/jlove/data/rat_seq/6cam/mm_training\")\n",
    "formatted_datetime = datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "working_directory = (output_directory / 'rtmdet' / f\"{model_name}_{formatted_datetime}\")\n",
    "working_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621b8c6",
   "metadata": {},
   "source": [
    "# You shouldn't need to change anything below here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08856b-dedf-457d-9f15-25df27dd8c33",
   "metadata": {},
   "source": [
    "### Display compute / environment info (for future reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da41e9f-90d0-4433-82a8-6506a8d53eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f5ff4f-9f73-4788-a770-a57d813a25b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: /n/groups/datta/tim_sainburg/conda_envs/mmdeploy/bin/python3\n",
      "sys.platform: linux\n",
      "Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "numpy_random_seed: 2147483648\n",
      "GPU 0: Quadro RTX 6000\n",
      "CUDA_HOME: /n/groups/datta/tim_sainburg/conda_envs/mmdeploy\n",
      "NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "PyTorch: 2.1.1\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.16.1\n",
      "OpenCV: 4.10.0\n",
      "MMEngine: 0.10.1\n",
      "MMDetection: 3.2.0+b6631d1\n",
      "cuda version: 12.1\n",
      "compiler information: GCC 9.3\n",
      "torch version: 2.1.1 True\n",
      "torchvision version: 0.16.1\n",
      "mmpose version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from mmengine.utils import get_git_hash\n",
    "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
    "import sys\n",
    "import mmdet\n",
    "import torch, torchvision\n",
    "import mmpose\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "\n",
    "def collect_env():\n",
    "    \"\"\"Collect the information of the running environments.\"\"\"\n",
    "    env_info = collect_base_env()\n",
    "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
    "    return env_info\n",
    "\n",
    "print(f\"Environment: {sys.executable}\")\n",
    "for name, val in collect_env().items():\n",
    "    print(f'{name}: {val}')\n",
    "# Check Pytorch installation\n",
    "print('cuda version:', get_compiling_cuda_version())\n",
    "print('compiler information:', get_compiler_version())\n",
    "print('torch version:', torch.__version__, torch.cuda.is_available())\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "print('mmpose version:', mmpose.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2335730-d629-426e-ba64-a2af5fdfc9de",
   "metadata": {},
   "source": [
    "### Create the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b88ae16-49a2-48a5-8be8-b07fc586d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f50e8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(config_loc.as_posix())\n",
    "\n",
    "# set the dataset directory\n",
    "cfg.data_root = dataset_directory.as_posix()\n",
    "\n",
    "# set the working directory\n",
    "cfg.work_dir = working_directory.as_posix()\n",
    "\n",
    "# set head to only care about the mouse class\n",
    "cfg.model.bbox_head.num_classes = 1\n",
    "\n",
    "# set the metainfo\n",
    "cfg.metainfo = {\n",
    "    'classes': ('Mouse', ),\n",
    "    'palette': [\n",
    "        (220, 20, 60),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# specify the dataset\n",
    "cfg.dataset_type = 'CocoDataset'\n",
    "\n",
    "# load COCO pre-trained weight\n",
    "if use_pretrained_model:\n",
    "    cfg.load_from = pretrained_model.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4384375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.metainfo = cfg.metainfo\n",
    "cfg.train_dataloader.dataset.data_prefix = dict(img='train/')\n",
    "cfg.train_dataloader.dataset.ann_file = 'annotations/instances_train.json'\n",
    "\n",
    "\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "cfg.val_dataloader.dataset.data_prefix = dict(img='val/')\n",
    "cfg.val_dataloader.dataset.ann_file = 'annotations/instances_val.json'\n",
    "\n",
    "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
    "\n",
    "cfg.val_evaluator.ann_file= cfg.data_root + '/annotations/instances_val.json'\n",
    "cfg.test_evaluator.ann_file= cfg.data_root + '/annotations/instances_val.json'\n",
    "\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 15\n",
    "cfg.default_hooks.checkpoint.interval = 50\n",
    "\n",
    "cfg.max_epochs = 2000\n",
    "cfg.train_cfg.max_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9af39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'RTMDet', 'data_preprocessor': {'type': 'DetDataPreprocessor', 'mean': [103.53, 116.28, 123.675], 'std': [57.375, 57.12, 58.395], 'bgr_to_rgb': False, 'batch_augments': None}, 'backbone': {'type': 'CSPNeXt', 'arch': 'P5', 'expand_ratio': 0.5, 'deepen_factor': 0.33, 'widen_factor': 0.5, 'channel_attention': True, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}, 'init_cfg': {'type': 'Pretrained', 'prefix': 'backbone.', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth'}}, 'neck': {'type': 'CSPNeXtPAFPN', 'in_channels': [128, 256, 512], 'out_channels': 128, 'num_csp_blocks': 1, 'expand_ratio': 0.5, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'bbox_head': {'type': 'RTMDetSepBNHead', 'num_classes': 1, 'in_channels': 128, 'stacked_convs': 2, 'feat_channels': 128, 'anchor_generator': {'type': 'MlvlPointGenerator', 'offset': 0, 'strides': [8, 16, 32]}, 'bbox_coder': {'type': 'DistancePointBBoxCoder'}, 'loss_cls': {'type': 'QualityFocalLoss', 'use_sigmoid': True, 'beta': 2.0, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'with_objectness': False, 'exp_on_reg': False, 'share_conv': True, 'pred_kernel_size': 1, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'train_cfg': {'assigner': {'type': 'DynamicSoftLabelAssigner', 'topk': 13}, 'allowed_border': -1, 'pos_weight': -1, 'debug': False}, 'test_cfg': {'nms_pre': 30000, 'min_bbox_size': 0, 'score_thr': 0.001, 'nms': {'type': 'nms', 'iou_threshold': 0.65}, 'max_per_img': 300}}\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c487da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save configuration file for future reference\n",
    "cfg.dump(working_directory / 'config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "213c3ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/datta/jlove/data/rat_seq/6cam/mm_training/rtmdet/rtmdet_small_8xb32-300e_coco_rat_24-08-26-23-29-19\n"
     ]
    }
   ],
   "source": [
    "print(working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5f372-532d-41d9-969d-8555f0e94031",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd6da74-6e2b-4170-aaad-3aefb6112d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.runner import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cedace2-40ea-4301-89fb-266aaf7a7101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/26 23:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 306267717\n",
      "    GPU 0: Quadro RTX 6000\n",
      "    CUDA_HOME: /n/groups/datta/tim_sainburg/conda_envs/mmdeploy\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "    PyTorch: 2.1.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.1\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 306267717\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/26 23:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "base_lr = 0.004\n",
      "checkpoint = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth'\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0002,\n",
      "        priority=49,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "    dict(\n",
      "        switch_epoch=280,\n",
      "        switch_pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='RandomCrop'),\n",
      "            dict(type='YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='PipelineSwitchHook'),\n",
      "]\n",
      "data_root = '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=50, max_keep_ckpts=15, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "interval = 10\n",
      "load_from = '/n/groups/datta/tim_sainburg/projects/24-01-05-multicamera_keypoints_mm2d/models/rtmdet/rtmdet_tiny_8xb32-300e_coco_24-01-05-11-25-00_102726/epoch_300.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 2000\n",
      "metainfo = dict(\n",
      "    classes=('Mouse', ), palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        arch='P5',\n",
      "        channel_attention=True,\n",
      "        deepen_factor=0.33,\n",
      "        expand_ratio=0.5,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth',\n",
      "            prefix='backbone.',\n",
      "            type='Pretrained'),\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        type='CSPNeXt',\n",
      "        widen_factor=0.5),\n",
      "    bbox_head=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        anchor_generator=dict(\n",
      "            offset=0, strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ], type='MlvlPointGenerator'),\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
      "        exp_on_reg=False,\n",
      "        feat_channels=128,\n",
      "        in_channels=128,\n",
      "        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_classes=1,\n",
      "        pred_kernel_size=1,\n",
      "        share_conv=True,\n",
      "        stacked_convs=2,\n",
      "        type='RTMDetSepBNHead',\n",
      "        with_objectness=False),\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=None,\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        expand_ratio=0.5,\n",
      "        in_channels=[\n",
      "            128,\n",
      "            256,\n",
      "            512,\n",
      "        ],\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_csp_blocks=1,\n",
      "        out_channels=128,\n",
      "        type='CSPNeXtPAFPN'),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        min_bbox_size=0,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1),\n",
      "    type='RTMDet')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.004, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1000, start_factor=1e-05,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=150,\n",
      "        begin=150,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=300,\n",
      "        eta_min=0.0002,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "stage2_num_epochs = 20\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=5,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file=\n",
      "    '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata/annotations/instances_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Resize'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    dynamic_intervals=[\n",
      "        (\n",
      "            280,\n",
      "            1,\n",
      "        ),\n",
      "    ],\n",
      "    max_epochs=2000,\n",
      "    type='EpochBasedTrainLoop',\n",
      "    val_interval=10)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=None,\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root=\n",
      "        '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes=('Mouse', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(img_scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), pad_val=114.0, type='CachedMosaic'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    1280,\n",
      "                    1280,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='RandomCrop'),\n",
      "            dict(type='YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                max_cached_images=20,\n",
      "                pad_val=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                ),\n",
      "                ratio_range=(\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                ),\n",
      "                type='CachedMixUp'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(img_scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), pad_val=114.0, type='CachedMosaic'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1280,\n",
      "            1280,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=20,\n",
      "        pad_val=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        ),\n",
      "        ratio_range=(\n",
      "            1.0,\n",
      "            1.0,\n",
      "        ),\n",
      "        type='CachedMixUp'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "train_pipeline_stage2 = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),\n",
      "    type='DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ), type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='RandomFlip'),\n",
      "                dict(prob=0.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    pad_val=dict(img=(\n",
      "                        114,\n",
      "                        114,\n",
      "                        114,\n",
      "                    )),\n",
      "                    size=(\n",
      "                        960,\n",
      "                        960,\n",
      "                    ),\n",
      "                    type='Pad'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=5,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root=\n",
      "        '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata',\n",
      "        metainfo=dict(classes=('Mouse', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata/annotations/instances_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/n/groups/datta/jlove/data/rat_seq/6cam/mm_training/rtmdet/rtmdet_small_8xb32-300e_coco_rat_24-08-26-23-29-19'\n",
      "\n",
      "08/26 23:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/26 23:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(NORMAL      ) PipelineSwitchHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "# build the runner from config\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "459ed934-8e51-43ed-b2f5-a6bd2e37a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: /n/groups/datta/tim_sainburg/projects/mmdetection/configs/rtmdet/rtmdet_s_8xb32-300e_coco.py): {'default_scope': 'mmdet', 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 50}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 50, 'max_keep_ckpts': 15}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'visualization': {'type': 'DetVisualizationHook'}}, 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'DetLocalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}], 'name': 'visualizer'}, 'log_processor': {'type': 'LogProcessor', 'window_size': 50, 'by_epoch': True}, 'log_level': 'INFO', 'load_from': '/n/groups/datta/tim_sainburg/projects/24-01-05-multicamera_keypoints_mm2d/models/rtmdet/rtmdet_tiny_8xb32-300e_coco_24-01-05-11-25-00_102726/epoch_300.pth', 'resume': False, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 2000, 'val_interval': 10, 'dynamic_intervals': [(280, 1)]}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'LinearLR', 'start_factor': 1e-05, 'by_epoch': False, 'begin': 0, 'end': 1000}, {'type': 'CosineAnnealingLR', 'eta_min': 0.0002, 'begin': 150, 'end': 300, 'T_max': 150, 'by_epoch': True, 'convert_to_iter_based': True}], 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'AdamW', 'lr': 0.004, 'weight_decay': 0.05}, 'paramwise_cfg': {'norm_decay_mult': 0, 'bias_decay_mult': 0, 'bypass_duplicate': True}}, 'auto_scale_lr': {'enable': False, 'base_batch_size': 16}, 'dataset_type': 'CocoDataset', 'data_root': '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata', 'backend_args': None, 'train_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'img_scale': (640, 640), 'pad_val': 114.0}, {'type': 'RandomResize', 'scale': (1280, 1280), 'ratio_range': (0.5, 2.0), 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': (640, 640)}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'CachedMixUp', 'img_scale': (640, 640), 'ratio_range': (1.0, 1.0), 'max_cached_images': 20, 'pad_val': (114, 114, 114)}, {'type': 'PackDetInputs'}], 'test_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'train_dataloader': {'batch_size': 32, 'num_workers': 10, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'batch_sampler': None, 'dataset': {'type': 'CocoDataset', 'data_root': '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata', 'ann_file': 'annotations/instances_train.json', 'data_prefix': {'img': 'train/'}, 'filter_cfg': {'filter_empty_gt': True, 'min_size': 32}, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'img_scale': (640, 640), 'pad_val': 114.0}, {'type': 'RandomResize', 'scale': (1280, 1280), 'ratio_range': (0.5, 2.0), 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': (640, 640)}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'CachedMixUp', 'img_scale': (640, 640), 'ratio_range': (1.0, 1.0), 'max_cached_images': 20, 'pad_val': (114, 114, 114)}, {'type': 'PackDetInputs'}], 'backend_args': None, 'metainfo': {'classes': ('Mouse',), 'palette': [(220, 20, 60)]}}, 'pin_memory': True}, 'val_dataloader': {'batch_size': 5, 'num_workers': 10, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata', 'ann_file': 'annotations/instances_val.json', 'data_prefix': {'img': 'val/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None, 'metainfo': {'classes': ('Mouse',), 'palette': [(220, 20, 60)]}}}, 'test_dataloader': {'batch_size': 5, 'num_workers': 10, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': 'data/coco/', 'ann_file': 'annotations/instances_val2017.json', 'data_prefix': {'img': 'val2017/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None}}, 'val_evaluator': {'type': 'CocoMetric', 'ann_file': '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata/annotations/instances_val.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None, 'proposal_nums': (100, 1, 10)}, 'test_evaluator': {'type': 'CocoMetric', 'ann_file': '/n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata/annotations/instances_val.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None, 'proposal_nums': (100, 1, 10)}, 'tta_model': {'type': 'DetTTAModel', 'tta_cfg': {'nms': {'type': 'nms', 'iou_threshold': 0.6}, 'max_per_img': 100}}, 'img_scales': [(640, 640), (320, 320), (960, 960)], 'tta_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': (640, 640), 'keep_ratio': True}, {'type': 'Resize', 'scale': (320, 320), 'keep_ratio': True}, {'type': 'Resize', 'scale': (960, 960), 'keep_ratio': True}], [{'type': 'RandomFlip', 'prob': 1.0}, {'type': 'RandomFlip', 'prob': 0.0}], [{'type': 'Pad', 'size': (960, 960), 'pad_val': {'img': (114, 114, 114)}}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction')}]]}], 'model': {'type': 'RTMDet', 'data_preprocessor': {'type': 'DetDataPreprocessor', 'mean': [103.53, 116.28, 123.675], 'std': [57.375, 57.12, 58.395], 'bgr_to_rgb': False, 'batch_augments': None}, 'backbone': {'type': 'CSPNeXt', 'arch': 'P5', 'expand_ratio': 0.5, 'deepen_factor': 0.33, 'widen_factor': 0.5, 'channel_attention': True, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}, 'init_cfg': {'type': 'Pretrained', 'prefix': 'backbone.', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth'}}, 'neck': {'type': 'CSPNeXtPAFPN', 'in_channels': [128, 256, 512], 'out_channels': 128, 'num_csp_blocks': 1, 'expand_ratio': 0.5, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'bbox_head': {'type': 'RTMDetSepBNHead', 'num_classes': 1, 'in_channels': 128, 'stacked_convs': 2, 'feat_channels': 128, 'anchor_generator': {'type': 'MlvlPointGenerator', 'offset': 0, 'strides': [8, 16, 32]}, 'bbox_coder': {'type': 'DistancePointBBoxCoder'}, 'loss_cls': {'type': 'QualityFocalLoss', 'use_sigmoid': True, 'beta': 2.0, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'with_objectness': False, 'exp_on_reg': False, 'share_conv': True, 'pred_kernel_size': 1, 'norm_cfg': {'type': 'SyncBN'}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'train_cfg': {'assigner': {'type': 'DynamicSoftLabelAssigner', 'topk': 13}, 'allowed_border': -1, 'pos_weight': -1, 'debug': False}, 'test_cfg': {'nms_pre': 30000, 'min_bbox_size': 0, 'score_thr': 0.001, 'nms': {'type': 'nms', 'iou_threshold': 0.65}, 'max_per_img': 300}}, 'train_pipeline_stage2': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': (640, 640), 'ratio_range': (0.5, 2.0), 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': (640, 640)}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'PackDetInputs'}], 'max_epochs': 2000, 'stage2_num_epochs': 20, 'base_lr': 0.004, 'interval': 10, 'custom_hooks': [{'type': 'EMAHook', 'ema_type': 'ExpMomentumEMA', 'momentum': 0.0002, 'update_buffers': True, 'priority': 49}, {'type': 'PipelineSwitchHook', 'switch_epoch': 280, 'switch_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': (640, 640), 'ratio_range': (0.5, 2.0), 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': (640, 640)}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'Pad', 'size': (640, 640), 'pad_val': {'img': (114, 114, 114)}}, {'type': 'PackDetInputs'}]}], 'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth', 'work_dir': '/n/groups/datta/jlove/data/rat_seq/6cam/mm_training/rtmdet/rtmdet_small_8xb32-300e_coco_rat_24-08-26-23-29-19', 'metainfo': {'classes': ('Mouse',), 'palette': [(220, 20, 60)]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b854aa4a-ae6b-4b22-888b-f20c6c143b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations  calib_params  train  val\n"
     ]
    }
   ],
   "source": [
    "!ls /n/groups/datta/jlove/data/rat_seq/6cam/detection_training/08-26-24-rat_6cam_alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26d04b-d9eb-40ba-a8eb-8a1f87b502b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0\n",
      "08/26 23:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "08/26 23:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone. in model from: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-s_imagenet_600e.pth\n",
      "Loads checkpoint by local backend from path: /n/groups/datta/tim_sainburg/projects/24-01-05-multicamera_keypoints_mm2d/models/rtmdet/rtmdet_tiny_8xb32-300e_coco_24-01-05-11-25-00_102726/epoch_300.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.stem.0.conv.weight: copying a param with shape torch.Size([12, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n",
      "size mismatch for backbone.stem.0.bn.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.conv.weight: copying a param with shape torch.Size([12, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n",
      "size mismatch for backbone.stem.1.bn.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.2.conv.weight: copying a param with shape torch.Size([24, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n",
      "size mismatch for backbone.stem.2.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.0.conv.weight: copying a param with shape torch.Size([48, 24, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n",
      "size mismatch for backbone.stage1.0.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.main_conv.conv.weight: copying a param with shape torch.Size([24, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.conv.weight: copying a param with shape torch.Size([24, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.final_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([24, 24, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([24, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 5, 5]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([24, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.0.conv.weight: copying a param with shape torch.Size([96, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "size mismatch for backbone.stage2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.main_conv.conv.weight: copying a param with shape torch.Size([48, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.conv.weight: copying a param with shape torch.Size([48, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.final_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([48, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 1, 5, 5]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.0.conv.weight: copying a param with shape torch.Size([192, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "size mismatch for backbone.stage3.0.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.main_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.0.conv.weight: copying a param with shape torch.Size([384, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n",
      "size mismatch for backbone.stage4.0.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv1.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.main_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.final_conv.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([192, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 1, 5, 5]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.reduce_layers.0.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.reduce_layers.0.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.1.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.reduce_layers.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.conv.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.conv.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.conv.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.conv.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([48, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 1, 5, 5]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.downsamples.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.downsamples.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for neck.downsamples.1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([192, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 1, 5, 5]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.out_convs.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.out_convs.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.conv.weight: copying a param with shape torch.Size([96, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n",
      "size mismatch for neck.out_convs.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.conv.weight: copying a param with shape torch.Size([96, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 3, 3]).\n",
      "size mismatch for neck.out_convs.2.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.0.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.1.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.2.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "missing keys in source state_dict: backbone.stage2.1.blocks.1.conv1.conv.weight, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_var, backbone.stage3.1.blocks.1.conv1.conv.weight, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_var\n",
      "\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.stem.0.conv.weight: copying a param with shape torch.Size([12, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n",
      "size mismatch for backbone.stem.0.bn.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.0.bn.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.conv.weight: copying a param with shape torch.Size([12, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n",
      "size mismatch for backbone.stem.1.bn.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.1.bn.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "size mismatch for backbone.stem.2.conv.weight: copying a param with shape torch.Size([24, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n",
      "size mismatch for backbone.stem.2.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stem.2.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.0.conv.weight: copying a param with shape torch.Size([48, 24, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n",
      "size mismatch for backbone.stage1.0.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.0.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.main_conv.conv.weight: copying a param with shape torch.Size([24, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.conv.weight: copying a param with shape torch.Size([24, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.final_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([24, 24, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([24, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 5, 5]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([24, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.0.conv.weight: copying a param with shape torch.Size([96, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "size mismatch for backbone.stage2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.main_conv.conv.weight: copying a param with shape torch.Size([48, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.conv.weight: copying a param with shape torch.Size([48, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.final_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([48, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 1, 5, 5]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.0.conv.weight: copying a param with shape torch.Size([192, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "size mismatch for backbone.stage3.0.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.0.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.main_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.0.conv.weight: copying a param with shape torch.Size([384, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n",
      "size mismatch for backbone.stage4.0.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.0.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv1.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.1.conv2.conv.weight: copying a param with shape torch.Size([384, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.main_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.final_conv.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([192, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 1, 5, 5]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.reduce_layers.0.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.reduce_layers.0.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.0.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.reduce_layers.1.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.reduce_layers.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.reduce_layers.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.conv.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.conv.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.conv.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.main_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.conv.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.short_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.final_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([48, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([48, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 1, 5, 5]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([48, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for neck.downsamples.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.downsamples.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.downsamples.1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for neck.downsamples.1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.downsamples.1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.main_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.conv.weight: copying a param with shape torch.Size([96, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.short_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.final_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([96, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([128, 1, 5, 5]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([96, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.main_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.conv.weight: copying a param with shape torch.Size([192, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.short_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.conv.weight: copying a param with shape torch.Size([384, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.final_conv.bn.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([192, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([192, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 1, 5, 5]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([192, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for neck.out_convs.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for neck.out_convs.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.conv.weight: copying a param with shape torch.Size([96, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n",
      "size mismatch for neck.out_convs.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.conv.weight: copying a param with shape torch.Size([96, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 3, 3]).\n",
      "size mismatch for neck.out_convs.2.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for neck.out_convs.2.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.0.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.1.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.cls_convs.2.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.0.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.1.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.0.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.conv.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.reg_convs.2.1.bn.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([1, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.0.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.1.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_reg.2.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 128, 1, 1]).\n",
      "missing keys in source state_dict: backbone.stage2.1.blocks.1.conv1.conv.weight, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_var, backbone.stage3.1.blocks.1.conv1.conv.weight, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_var\n",
      "\n",
      "08/26 23:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /n/groups/datta/tim_sainburg/projects/24-01-05-multicamera_keypoints_mm2d/models/rtmdet/rtmdet_tiny_8xb32-300e_coco_24-01-05-11-25-00_102726/epoch_300.pth\n",
      "08/26 23:29:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/26 23:29:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/26 23:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /n/groups/datta/jlove/data/rat_seq/6cam/mm_training/rtmdet/rtmdet_small_8xb32-300e_coco_rat_24-08-26-23-29-19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/n/groups/datta/tim_sainburg/conda_envs/mmdeploy/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449201336/work/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83163ac2-2902-41ce-a055-106af302ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364f7f3-b725-4bd2-984c-680646292a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdeploy",
   "language": "python",
   "name": "mmdeploy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
